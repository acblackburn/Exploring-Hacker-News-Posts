{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Hacker News Posts\n",
    "\n",
    "Hacker News is a site and startup backed by Y Combinator. The site functions in a similar way to reddit where users post content and other users vote, comment on and discuss the content. Hacker News is especially popular within Technology and Startup circles and some of the top posts generate a large amount of traffic, often drawing hundreds of thousands of visitors.\n",
    "\n",
    "The aim of this project will be to determine what types of post recieve more comments on average, Specifically whether 'Ask HN' or 'Show HN' posts recieve more comments. 'Ask HN' are posts were a user asks the Hacker News community questions. 'Show HN' are posts where a user shares something with the community.\n",
    "\n",
    "Additionally, it will be investigated whether posting at certain times recieves more comments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opening and Expoloring the Data\n",
    "\n",
    "The data used for this project is taken from a 12 month period between Spetember 2015 and September 2016. The original dataset contained almost 300,000 posts but has been reduced down to 20,000 posts by removing posts with no comments and then taking a random sample from the remaining entries. The dataset can be found [here](https://www.kaggle.com/hacker-news/hacker-news-posts) on Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import reader\n",
    "\n",
    "openfile = open('hacker_news.csv', encoding='utf8')\n",
    "readfile = reader(openfile)\n",
    "hn = list(readfile) ## Create a list of lists from data\n",
    "\n",
    "hn_header = hn[0] # split header row from main body of data\n",
    "hn_data = hn[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To aid in data analysis, a function `explore_data` will be used repeatedly to visualise the data more clearly. It is defined below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_data(dataset, start, end, rows_and_columns=False):\n",
    "    dataset_slice = dataset[start:end]    \n",
    "    for row in dataset_slice:\n",
    "        print(row)\n",
    "        print('\\n') # adds a new (empty) line after each row\n",
    "\n",
    "    if rows_and_columns:\n",
    "        print('Number of rows:', len(dataset))\n",
    "        print('Number of columns:', len(dataset[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin, the first five rows of the dataset will be explored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n",
      "\n",
      "\n",
      "['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52']\n",
      "\n",
      "\n",
      "['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30']\n",
      "\n",
      "\n",
      "['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20']\n",
      "\n",
      "\n",
      "['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01']\n",
      "\n",
      "\n",
      "['10301696', 'Note by Note: The Making of Steinway L1037 (2007)', 'http://www.nytimes.com/2007/11/07/movies/07stein.html?_r=0', '8', '2', 'walterbell', '9/30/2015 4:12']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(hn_header)\n",
    "print('\\n')\n",
    "explore_data(hn_data, 0, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering the Data\n",
    "\n",
    "Below, the data is filtered into 3 lists based on whether the post is 'Ask HN', 'Show HN', or neither of the two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ask posts: 1744\n",
      "Number of show posts: 1162\n",
      "Number of other posts: 17194\n"
     ]
    }
   ],
   "source": [
    "ask_posts = []\n",
    "show_posts = []\n",
    "other_posts = []\n",
    "\n",
    "for row in hn_data:\n",
    "    title = row[1]\n",
    "    title = title.lower()\n",
    "    if title.startswith('ask hn'):\n",
    "        ask_posts.append(row)\n",
    "    elif title.startswith('show hn'):\n",
    "        show_posts.append(row)\n",
    "    else:\n",
    "        other_posts.append(row)\n",
    "        \n",
    "print('Number of ask posts: ' + str(len(ask_posts)))\n",
    "print('Number of show posts: ' + str(len(show_posts)))\n",
    "print('Number of other posts: ' + str(len(other_posts)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen above, There are just under 300,000 posts, with a minority of them being ask or show posts. There are about 10% more show posts than ask posts in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the Average Number of Comments for 'Ask HN' and 'Show HN' Posts\n",
    "\n",
    "Next, the total and average number of comments will be determined for both the ask post and show post data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 'Ask HN' Comments: 24483\n",
      "Average 'Ask HN' Comments: 14.038417431192661\n",
      "\n",
      "Total 'Show HN' Comments: 11988\n",
      "Average 'Show Hn' Comments: 10.31669535283993\n"
     ]
    }
   ],
   "source": [
    "total_ask_comments = 0\n",
    "\n",
    "for row in ask_posts:\n",
    "    num_comments = int(row[4])\n",
    "    total_ask_comments += num_comments\n",
    "    \n",
    "avg_ask_comments = total_ask_comments / len(ask_posts)\n",
    "\n",
    "print(\"Total 'Ask HN' Comments: \" + str(total_ask_comments))\n",
    "print(\"Average 'Ask HN' Comments: \" + str(avg_ask_comments) + '\\n')\n",
    "\n",
    "total_show_comments = 0\n",
    "\n",
    "for row in show_posts:\n",
    "    num_comments = int(row[4])\n",
    "    total_show_comments += num_comments\n",
    "    \n",
    "avg_show_comments = total_show_comments / len(show_posts)\n",
    "\n",
    "print(\"Total 'Show HN' Comments: \" + str(total_show_comments))\n",
    "print(\"Average 'Show Hn' Comments: \" + str(avg_show_comments))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After analysing both 'Ask HN' and 'Show HN' data as above, it can be seen that 'Ask HN' has far more user interaction with almost double the amount of total comments and over double the amount of average comments per post.\n",
    "\n",
    "This is likely due to how an ask post is naturally going to create more discussion. Users are more likely to respond to a post when it is a direct question rather than a project, fact or general information sharing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the Average Number of Comments of 'Ask HN' Posts by Hour\n",
    "\n",
    "The following code cells will calculate the average number of comments an 'Ask HN' post revieves based on which hour of the day it was created in (US Eastern Time). This is so that it can be determined which hours of the day are best to make a post on Hacker News to recieve the most user interation.\n",
    "\n",
    "The code cell below creates two frequency tables: once for the number of posts by hour (`counts_by_hour`) and one for the number of comments by hour (`comments_by_hour`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "\n",
    "result_list = []\n",
    "\n",
    "for row in ask_posts:\n",
    "    result_list.append([row[6], int(row[4])])\n",
    "    \n",
    "counts_by_hour = {} # Create empty freq. table for posts by hour\n",
    "comments_by_hour = {} # Create empty freq. table comments by hour\n",
    "\n",
    "for row in result_list:\n",
    "    time = row[0]\n",
    "    time = time.split(' ')[1] # Single out time\n",
    "    \n",
    "    if len(time) == 4:\n",
    "        time = '0' + time # Zero pad the hour where hour < 10\n",
    "\n",
    "    time = dt.datetime.strptime(time, \"%H:%M\")\n",
    "    hour = time.strftime(\"%H\")\n",
    "    \n",
    "    if hour not in counts_by_hour: # Populate both frequency tables\n",
    "        counts_by_hour[hour] = 1\n",
    "        comments_by_hour[hour] = row[1]\n",
    "    else:\n",
    "        counts_by_hour[hour] += 1\n",
    "        comments_by_hour[hour] += row[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After creating both of the frequency tables as above, a list of lists of the hour of the day and average number of comments per post per hour will be created as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['09', 5.5777777777777775],\n",
       " ['13', 14.741176470588234],\n",
       " ['10', 13.440677966101696],\n",
       " ['14', 13.233644859813085],\n",
       " ['16', 16.796296296296298],\n",
       " ['23', 7.985294117647059],\n",
       " ['12', 9.41095890410959],\n",
       " ['17', 11.46],\n",
       " ['15', 38.5948275862069],\n",
       " ['21', 16.009174311926607],\n",
       " ['20', 21.525],\n",
       " ['02', 23.810344827586206],\n",
       " ['18', 13.20183486238532],\n",
       " ['03', 7.796296296296297],\n",
       " ['05', 10.08695652173913],\n",
       " ['19', 10.8],\n",
       " ['01', 11.383333333333333],\n",
       " ['22', 6.746478873239437],\n",
       " ['08', 10.25],\n",
       " ['04', 7.170212765957447],\n",
       " ['00', 8.127272727272727],\n",
       " ['06', 9.022727272727273],\n",
       " ['07', 7.852941176470588],\n",
       " ['11', 11.051724137931034]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_by_hour = []\n",
    "\n",
    "for hour in counts_by_hour:\n",
    "    comments_hourly = comments_by_hour[hour] / counts_by_hour[hour]\n",
    "    avg_by_hour.append([hour, comments_hourly])\n",
    "    \n",
    "avg_by_hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To sort the this list of lists based on the average number of comments, the indecies must be swapped for every row, then the whole list be sorted using the `sorted()` function and setting `reverse=True` to sort in descending order.\n",
    "\n",
    "After the list has been sorted, the top 5 hours will be formatted and printed in an easy to read way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5.5777777777777775, '09'],\n",
       " [14.741176470588234, '13'],\n",
       " [13.440677966101696, '10'],\n",
       " [13.233644859813085, '14'],\n",
       " [16.796296296296298, '16'],\n",
       " [7.985294117647059, '23'],\n",
       " [9.41095890410959, '12'],\n",
       " [11.46, '17'],\n",
       " [38.5948275862069, '15'],\n",
       " [16.009174311926607, '21'],\n",
       " [21.525, '20'],\n",
       " [23.810344827586206, '02'],\n",
       " [13.20183486238532, '18'],\n",
       " [7.796296296296297, '03'],\n",
       " [10.08695652173913, '05'],\n",
       " [10.8, '19'],\n",
       " [11.383333333333333, '01'],\n",
       " [6.746478873239437, '22'],\n",
       " [10.25, '08'],\n",
       " [7.170212765957447, '04'],\n",
       " [8.127272727272727, '00'],\n",
       " [9.022727272727273, '06'],\n",
       " [7.852941176470588, '07'],\n",
       " [11.051724137931034, '11']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swap_avg_by_hour = []\n",
    "\n",
    "for row in avg_by_hour:\n",
    "    swap_avg_by_hour.append([row[1], row[0]])\n",
    "    \n",
    "swap_avg_by_hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Hours for 'Ask HN' Post Comments:\n",
      "15:00: 38.59 average comments per post.\n",
      "02:00: 23.81 average comments per post.\n",
      "20:00: 21.52 average comments per post.\n",
      "16:00: 16.80 average comments per post.\n",
      "21:00: 16.01 average comments per post.\n"
     ]
    }
   ],
   "source": [
    "sorted_swap = sorted(swap_avg_by_hour, reverse=True)\n",
    "\n",
    "print(\"Top 5 Hours for 'Ask HN' Post Comments:\")\n",
    "\n",
    "for avg, hour in sorted_swap[:5]:\n",
    "    \n",
    "    time_format = dt.datetime.strptime(hour, \"%H\")\n",
    "    time_format = time_format.strftime(\"%H:%M\")\n",
    "    \n",
    "    print(\"{time}: {average:.2f} average comments per post.\".format(average=avg, time=time_format))\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen above, the hour that revieves the most comments per 'Ask HN' post is `15:00` with almost 40 comments per post. This is a large increase over `02:00` with just under 24 comments per post. \n",
    "\n",
    "At a first glance, 2AM coming in second place seems strange, however it is worth mentioning that this data is in US eastern time. When it is 2AM in the US, it is 4PM in Japan for example, so this could be highlighting the best time to comment based on the audience of which timezone is being targeted.\n",
    "\n",
    "In the UK for example, if targeting a western audience in the US, it can then be concluded that to maximise user interation with 'Ask HN' posts, posts should be created at around 20:00 GMT or 8PM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion \n",
    "\n",
    "From this project, it has been concluded that from posts recieving comments, the post should be an 'Ask HN' post as they recieve around double the average amount of comments when compared to 'Show HN' posts.\n",
    "\n",
    "It can also been determined that the best time to post an 'Ask HN' post is at 8PM GMT for UK users as this maximises user engagement with a western audience. It is worth remebering how the data has been filtered to disregard posts that have no comments. Therefore it should be made clear that these conclusions only apply to posts that recieve comments to begin with."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
